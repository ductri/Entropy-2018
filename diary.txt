14:57 17-06-2018
- Download dataset
- Reading final round's description
- Considering IDE: juputer notebook or pycharm --> pycharm, because suggestion is the best way for coding fast.
- Data descriptions: 
+ 3 files, negative, neutral and positive. Each csv file contains 1 column. Each row is a sentence, especially, sentences may be in accented or not. 
+ Each row is just a sentence: need to confirm, that mean, it contains almost 1 dot. And thus, the input will not be too long. Anw, we need a statistic here: sentence long.
+ About accent: A simple idea is remove all accents. More complicated one is predict accents and fill out them to non-accented sentences.
+ According to the problem description in pdf file, there are approximately 150k sentences for all classes, 44.1 MB in size, not so much
+ In addition, organizer also provides list of stop words in vietnamese. 
- Merge 3 files into one
- Export some statistics to have some intuition at data.

16:56 18-06-2018
- Do data description
- TODO: remove too long mention, maybe 1000 as threshold
- Lengh of negative is the longest one, and twice longer than neutral ?
- Data training is quite balance between 3 labels
- do preprocesses
- split data to do validation

00:03 20-06-2018
- Coding skeleton: model_v1.py

- Preprocess
- Build vocabulary + OUT_OF_SCOPE
- Get one-hot index vector
- Build graph, start with a Placeholder in Max Length of a Sentence dimension, followed by transforming matrix, end with 3 nodes

--> Let's build graph first

Step 1: Coding skeleton
Aim to have a runnable version as soon as possible
- Need summary log
- TODO Need data to feed --> preprocess data
- TODO [Maybe next step] Need summary performance on training and evaluation set
11:16 20-06-2018
- Adding summary ops

19:18 20-06-2018
Boost the mood successfully

- Continue to adding summary ops
- Max Ram. Damm! Always remeber to limit resource before run, even dummy test.
- Ok, a simple code is on the board now.
- Let's move to text preprocessing, tedious works :33 
- This is the first try, try it as simple as possible to quickly have a prototype:
+ reuse code from previous round
+ What proportion of sentences without accents ? Not much. TODO consider remove/add accents
+ TODO: it's severe, vietnamese tokenizer doesn't work with non-accent sentences
- ref: https://towardsdatascience.com/training-and-visualising-word-vectors-2f946c6430f8
- ref: http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/